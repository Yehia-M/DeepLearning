{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bgPpghocFIa"
   },
   "source": [
    "# Emojify! \n",
    "\n",
    "Using word vector representations to build an Emojifier.\n",
    "\n",
    ">\"Congratulations on the promotion! Let's get coffee and talk. Love you!\"   \n",
    "\n",
    "The emojifier can automatically turn this into:\n",
    ">\"Congratulations on the promotion! üëç  Let's get coffee and talk. ‚òïÔ∏è Love you! ‚ù§Ô∏è\"\n",
    "\n",
    "it finds the most appropriate emoji to be used with this sentence (‚öæÔ∏è)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lMZ9xg8MFHZU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Av0PwZYscFIh"
   },
   "source": [
    "<a name='1'></a>\n",
    "## Baseline Model: Emojifier-V1\n",
    "\n",
    "<a name='1-1'></a>\n",
    "### Dataset EMOJISET\n",
    "\n",
    "Let's start by building a simple baseline classifier. \n",
    "\n",
    "You have a tiny dataset (X, Y) where:\n",
    "- X contains 127 sentences (strings).\n",
    "- Y contains an integer label between 0 and 4 corresponding to an emoji for each sentence.\n",
    "\n",
    "<img src=\"images/data_set.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center><font color='purple'><b>Figure </b>: EMOJISET - a classification problem with 5 classes. A few examples of sentences are given here. </center></caption>\n",
    "\n",
    "Load the dataset using the code below. The dataset is split between training (127 examples) and testing (56 examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2671,
     "status": "ok",
     "timestamp": 1611738624467,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "OvuoZ8pWcFIi"
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2046,
     "status": "ok",
     "timestamp": 1611738634135,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "DjAuDbxrcFIi"
   },
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2058,
     "status": "ok",
     "timestamp": 1611738637381,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "vE1Zd2SMcFIj",
    "outputId": "49f45ed1-8f2f-4ea8-da44-4acb41731287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÑ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n",
      "I love you mum ‚ù§Ô∏è\n",
      "Stop saying bullshit üòû\n",
      "congratulations on your acceptance üòÑ\n",
      "The assignment is too long  üòû\n",
      "I want to go play ‚öæ\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    print(X_train[idx], label_to_emoji(Y_train[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tS_N2pMpcFIk"
   },
   "source": [
    "<a name='1-2'></a>\n",
    "### Overview of the Emojifier-V1\n",
    "\n",
    "In this section, you'll implement a baseline model called \"Emojifier-v1\".  \n",
    "\n",
    "<center>\n",
    "<img src=\"images/image_1.png\" style=\"width:900px;height:300px;\">\n",
    "    <caption><center><font color='purple'><b>Figure</b>: Baseline model (Emojifier-V1).</center></caption>\n",
    "</center></font>\n",
    "\n",
    "\n",
    "#### Inputs and Outputs\n",
    "* The input of the model is a string corresponding to a sentence (e.g. \"I love you\"). \n",
    "* The output will be a probability vector of shape (1,5), (indicating that there are 5 emojis to choose from).\n",
    "* The (1,5) probability vector is passed to an argmax layer, which extracts the index of the emoji with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2619,
     "status": "ok",
     "timestamp": 1611738660835,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "RhRTRwVncFIm"
   },
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2838,
     "status": "ok",
     "timestamp": 1611738667164,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "GlHYeuBIcFIo",
    "outputId": "c2b73f6a-9a15-4728-a8b4-7ba38b5372ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 'I missed you' has label index 0, which is emoji ‚ù§Ô∏è\n",
      "Label index 0 in one-hot encoding format is [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "idx = 50\n",
    "print(f\"Sentence '{X_train[50]}' has label index {Y_train[idx]}, which is emoji {label_to_emoji(Y_train[idx])}\", )\n",
    "print(f\"Label index {Y_train[idx]} in one-hot encoding format is {Y_oh_train[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 8474,
     "status": "ok",
     "timestamp": 1611738705912,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "QXI3avt7cFIq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hoÿ£', 'ng', '-0.021476', '-0.46788', '-0.57489', '0.25384', '-0.83486', '-1.2622', '0.74499', '0.41843', '0.15076', '-0.3762', '0.31586', '1.0779', '0.26601', '-0.84584', '-0.21545', '-0.30827', '-1.0899', '-0.53668', '2.0235', '1.3613', '-0.9779', '-0.80162', '0.68561', '-0.18649', '-0.5215', '0.8261', '-0.1142', '-0.37842', '-0.70749', '-0.082986', '-0.54944', '-0.25965', '0.39062', '1.385', '0.35108', '0.75802', '0.064603', '1.0825', '-0.023899', '-0.59102', '0.16235', '-0.25107', '0.20679', '-0.12571', '-0.018305', '-0.91191', '-0.27518', '-1.3942', '0.9766', '-0.11565']\n",
      "['vis-ÿ£', '-vis', '-0.42222', '-0.17201', '-0.3977', '-0.47292', '0.1869', '-0.27254', '1.1996', '0.30363', '0.026903', '-0.25643', '0.43997', '0.43185', '0.11064', '0.071013', '-1.2559', '-0.17438', '0.39446', '0.17034', '0.78422', '0.10057', '-0.25143', '-0.54215', '-0.36984', '0.44356', '0.14029', '0.50077', '-0.41179', '-0.20118', '-0.070628', '0.67134', '-0.37876', '0.23519', '0.66533', '-0.04729', '-0.13505', '0.0080215', '-0.22851', '-0.11957', '-1.2082', '0.24583', '0.22041', '-0.70773', '0.25961', '0.24909', '-0.52742', '-0.43718', '-0.06806', '0.56763', '0.3998', '0.06423']\n",
      "['thÿ£', 'nh', '-0.149', '-0.53056', '-0.34744', '-1.1326', '-0.26678', '-0.75053', '1.7498', '0.79765', '-0.59799', '0.14863', '-0.66531', '-0.14717', '0.86788', '-0.81495', '-0.29532', '-0.21591', '-0.17822', '0.53032', '1.1974', '1.4063', '0.051583', '-1.8594', '-0.30998', '1.2946', '0.3113', '-0.21206', '0.39881', '0.12364', '-0.63458', '-0.21439', '-0.12953', '-0.88241', '1.6495', '1.1472', '-0.2385', '-0.45029', '-0.66858', '1.0771', '-0.33371', '-0.47602', '0.0071952', '-0.0018429', '0.16469', '0.10685', '-0.32819', '-1.4057', '0.41699', '-0.91552', '0.93435', '1.0798']\n",
      "['tÿ£', 'u', '-0.54221', '0.33787', '-0.26496', '0.34152', '-0.91987', '-0.38392', '0.84552', '1.0953', '0.19205', '0.5011', '0.67682', '-1.1036', '1.8836', '-0.99028', '-0.28134', '-0.40116', '-0.46097', '1.116', '-0.34527', '1.6797', '-0.27655', '-1.5659', '0.8284', '0.88921', '1.6831', '0.069708', '0.6357', '-0.15524', '0.83091', '-0.20163', '-1.0915', '0.58561', '-0.73725', '-0.27661', '-0.28396', '-0.21628', '0.36487', '1.1702', '-0.95023', '1.4699', '-0.091115', '-0.80865', '-0.36978', '-0.97807', '-0.26224', '0.40844', '0.081257', '0.19182', '0.52635', '-0.070596']\n",
      "['Ÿá⁄Ø≈íŸÜ¬∏\\xadŸà‚Ä∫¬∏√©‚Äì‚Ç¨ŸÜ¬∏‚ÄπŸá¬π¬≥√ß¬´', 'ŸÜÿõ‚Äπ', '-1.5442', '1.0971', '0.237', '-1.1728', '-1.3823', '1.4329', '1.0756', '-0.02997', '-1.1227', '0.74116', '0.069147', '2.3796', '0.040494', '0.74405', '-0.10661', '0.75547', '1.0712', '0.54329', '0.79097', '0.75868', '0.11788', '-0.81079', '-0.5307', '1.2267', '0.69961', '-0.48549', '1.0564', '0.29833', '0.52935', '-1.0508', '-0.21467', '0.83912', '-0.18817', '1.3517', '-0.4504', '-0.31094', '1.3158', '-0.40795', '-1.1396', '-1.0736', '0.64182', '-0.40398', '0.23191', '0.084808', '-1.8601', '-0.32268', '-0.19788', '0.40565', '1.5569', '1.2732']\n",
      "['fÿ£', 'bregas', '-0.27025', '0.55113', '0.10169', '-0.27947', '-0.15448', '-0.91837', '-0.22923', '0.66267', '0.59488', '1.6372', '1.5298', '0.74979', '-0.19703', '-0.36536', '0.19854', '0.19798', '0.17391', '-0.51903', '-0.64', '0.20086', '-0.71357', '0.18227', '0.28345', '-0.15906', '0.35641', '1.2545', '1.1105', '-0.40082', '1.3991', '0.83673', '-0.62258', '-0.31325', '-0.84386', '-0.077505', '1.2866', '1.2669', '0.37846', '0.73764', '-1.1057', '0.76891', '1.1932', '-0.18075', '-0.31923', '-0.22833', '0.31131', '-0.27654', '0.66765', '-0.32717', '0.033786', '-1.346']\n",
      "['gimnÿ£', 'stic', '0.46302', '0.5468', '-1.4414', '-1.109', '-1.2524', '0.23459', '-0.018532', '1.6092', '-1.2128', '1.047', '0.53637', '-0.89514', '-0.41566', '-0.41333', '-0.53666', '-0.58414', '0.90875', '-0.10774', '0.50249', '-0.40459', '-0.16472', '-0.37941', '-0.21072', '1.2651', '-2.853', '0.95759', '0.13525', '0.20431', '1.243', '1.4118', '-0.71813', '0.55297', '-1.8318', '-0.64257', '1.6776', '0.4902', '0.40837', '1.4091', '0.063706', '0.41293', '0.70151', '-0.67424', '0.33134', '-1.4154', '5.3572e-05', '0.57452', '-0.6657', '0.34539', '0.62055', '0.40598']\n",
      "['carnivÿ£', 'le', '0.93351', '-0.23521', '-0.34402', '0.33982', '-0.46164', '-0.1921', '0.5595', '0.62006', '0.23689', '0.62005', '-0.10931', '1.128', '-0.39557', '0.37783', '0.26547', '-1.2276', '-0.13446', '0.58346', '0.020112', '0.12053', '0.084229', '-0.50092', '0.15555', '-0.020281', '0.63389', '1.55', '-0.73987', '0.58715', '0.46817', '-0.066729', '-1.2513', '0.46865', '0.51618', '0.22336', '-0.7273', '-0.19181', '0.45971', '-0.81845', '-1.0524', '0.055298', '-0.40897', '-0.76393', '-0.66739', '-0.9355', '-1.1776', '-0.38482', '-0.35036', '0.63574', '0.36817', '1.0061']\n",
      "['xiÿ£', 'n', '-1.6149', '2.0718', '-1.8171', '1.4539', '0.95301', '-0.79162', '1.0819', '-0.39327', '0.42471', '-0.83812', '-0.47473', '1.064', '3.3194', '0.12114', '1.1258', '-0.80123', '-0.84331', '0.95936', '0.871', '0.74305', '-0.94692', '-1.2848', '-0.5845', '1.362', '0.92564', '-0.93057', '-0.3323', '-0.012029', '0.07411', '-1.5397', '-0.049012', '-0.45208', '-0.55624', '-0.30626', '0.28591', '0.35288', '-0.25302', '-0.25408', '-0.25372', '0.35643', '-0.31829', '0.66012', '1.7394', '0.4369', '-1.2049', '1.0642', '0.72291', '0.59339', '1.6707', '1.3743']\n",
      "['ÿ§‚Äòÿ£', 'i', '0.66186', '-0.83343', '-1.0657', '1.1254', '0.012644', '0.33218', '1.502', '0.60603', '-0.70976', '-0.11419', '-0.83618', '0.83981', '0.76418', '-1.1601', '-1.4753', '-0.66609', '-0.33513', '0.87299', '0.52373', '0.58199', '-0.28277', '-0.38934', '1.0662', '-0.32137', '0.92223', '0.39948', '-0.4101', '-1.2922', '-0.8895', '-0.82474', '-0.88464', '0.61433', '0.17081', '0.37184', '-0.096504', '0.011042', '-0.96341', '-0.024873', '0.54593', '1.1516', '0.36629', '-0.87951', '-0.58981', '0.88288', '1.0738', '0.28449', '-0.30631', '0.46106', '0.39664', '0.65464']\n",
      "['hoÿ£', 'i', '-1.3992', '0.8947', '-0.22168', '-0.36978', '-0.70604', '-1.3258', '1.6867', '-0.1077', '-0.15011', '0.25915', '-1.3054', '0.50371', '0.67728', '-0.97467', '-0.73573', '-0.85156', '-0.2254', '0.53564', '0.77648', '0.52331', '-0.39272', '-0.073118', '-0.25734', '-0.64046', '-0.46664', '0.51733', '-0.25244', '-0.068989', '-0.17706', '0.50769', '-0.92242', '-0.39463', '0.14507', '0.88602', '1.3544', '0.85821', '1.0091', '-0.6751', '-0.20262', '0.26102', '0.010189', '0.76402', '-0.15471', '-0.5446', '0.57735', '-0.48894', '0.084325', '-0.12706', '0.89662', '1.3005']\n",
      "['grÿ£', 'cia', '0.57803', '-0.3993', '0.31487', '-0.52207', '-0.39427', '-0.70032', '0.46632', '0.8218', '-0.48763', '0.37909', '0.73539', '-0.43891', '-0.40524', '-0.63637', '-0.7832', '-0.21437', '0.43439', '0.038677', '0.15805', '-0.55104', '-0.66771', '0.028499', '-0.3692', '1.1627', '-0.28312', '1.305', '-0.40658', '0.64104', '-0.16675', '0.29057', '-0.90879', '0.26462', '0.20202', '-0.81202', '0.9202', '-0.64917', '0.3562', '0.09502', '0.0094677', '0.31745', '0.39713', '0.013702', '0.10625', '-0.6698', '-2.003', '-0.46816', '0.22488', '-0.26252', '1.2908', '0.63313']\n",
      "['pointe-ÿ£', '-pitre', '-0.011569', '-0.72026', '-1.8361', '-0.39085', '-0.33829', '-0.030712', '0.67071', '0.0058467', '0.33996', '-0.53523', '0.34994', '-1.3907', '1.4059', '0.17334', '-0.19877', '-0.20223', '-0.1069', '-0.092793', '-0.8552', '0.85979', '0.18399', '-0.27664', '-1.1656', '1.1633', '-0.19276', '0.33102', '-0.06051', '0.55735', '-0.21581', '0.30492', '-1.0977', '0.60923', '0.0038328', '-0.24667', '-0.53108', '-0.14707', '-0.015919', '-0.43777', '-0.25295', '0.30851', '-0.35186', '0.48454', '0.58309', '-0.50833', '-0.96091', '0.2803', '0.72079', '-0.32731', '0.8375', '-0.25686']\n",
      "['hoÿ£', 'n', '-0.216', '-0.82854', '-0.51314', '-0.33695', '-1.1999', '-0.68747', '0.10912', '0.77359', '0.35785', '-0.031069', '0.21275', '0.53067', '1.3713', '-0.47017', '-0.37253', '0.80572', '-0.32293', '-0.42594', '0.4614', '0.80117', '-0.99427', '-0.85316', '0.22671', '-0.56555', '0.33122', '0.86256', '0.45952', '0.14391', '-0.81451', '-0.14379', '-1.0687', '-0.46405', '0.31064', '1.2398', '0.60321', '0.49033', '0.73432', '0.24195', '-0.10878', '-0.15563', '-0.10416', '0.15636', '-0.76811', '0.079723', '0.19265', '0.23986', '0.30314', '-0.017283', '-0.49792', '-0.1274']\n",
      "['tÿ£', 'pies', '0.33524', '0.4558', '0.31245', '-0.63515', '-0.11317', '-0.23636', '0.28773', '-0.022994', '-1.2043', '1.2993', '0.58017', '-0.11828', '0.15959', '-1.661', '-0.045498', '0.099493', '0.10209', '0.67551', '1.9362', '0.48605', '-0.44304', '-0.15794', '-0.52571', '-0.11418', '0.31758', '2.2614', '-0.59078', '-0.71633', '0.50614', '0.26741', '-0.40793', '0.6967', '-0.17375', '-0.16418', '0.43682', '1.4987', '0.34567', '0.89281', '0.88563', '0.48751', '0.71286', '-0.6689', '-1.3491', '-1.1994', '0.062766', '0.81491', '-0.2654', '-0.23638', '0.0062147', '-0.10436']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['toÿ£', 'n', '-0.3533', '-0.4358', '0.11817', '-1.0535', '-0.29671', '-0.25773', '0.44576', '0.88675', '0.6931', '-0.068022', '0.71864', '1.1021', '0.062304', '0.2429', '0.015502', '-0.50053', '-0.059542', '-0.44114', '1.5365', '2.4328', '-0.70958', '-0.4896', '1.4431', '-0.70438', '0.21793', '0.76289', '-0.74727', '-0.46647', '0.17421', '-0.4909', '-1.6048', '-1.0791', '-0.36426', '0.59699', '-0.73691', '-0.029122', '0.35328', '-0.44757', '-0.073127', '0.10793', '-0.25561', '-1.9499', '0.56167', '-1.1464', '0.08256', '-0.29649', '0.061186', '1.141', '-1.0297', '-0.00824']\n",
      "['ÿ§‚Äòÿ£', 'n', '-1.0644', '-0.23135', '-0.31926', '-0.42339', '0.061141', '-1.2617', '0.89346', '-0.22266', '0.55936', '0.098746', '0.0058627', '-0.028927', '1.7465', '0.81165', '-0.88142', '-0.51713', '0.69385', '0.89147', '0.7072', '0.28324', '-0.58291', '-1.2148', '-0.11982', '0.36119', '1.1338', '1.1659', '-0.29555', '0.34745', '-0.65052', '-0.36863', '-0.62046', '-0.47452', '0.28353', '1.2274', '-0.068288', '-0.26403', '0.90172', '-0.4482', '-0.80476', '1.1503', '-0.64119', '-0.46559', '-0.1907', '0.21403', '-0.0050543', '-0.84228', '0.24739', '0.80774', '0.2458', '0.83589']\n",
      "['bÿ£', 'ng', '-2.0851', '0.36082', '-0.41556', '0.99753', '-0.30461', '-2.1038', '-0.73452', '-0.90724', '-0.11735', '-0.87831', '-0.080375', '-0.67277', '1.2538', '-0.57889', '-0.065884', '0.10688', '-0.042481', '1.0167', '0.47003', '1.5485', '-0.93884', '-1.4514', '-0.18833', '-0.9952', '0.95729', '1.321', '-0.85124', '0.24064', '-0.61262', '-0.29418', '-0.7411', '-0.27845', '0.40276', '0.6887', '-0.95998', '0.39386', '0.0040116', '0.97593', '0.11969', '1.3325', '-1.3843', '-0.6408', '-1.6233', '0.8615', '-0.64196', '-0.83839', '-0.084333', '0.39837', '0.0087288', '0.041608']\n",
      "['cÿ£', 'rn', '0.11569', '0.73481', '-0.20356', '0.92946', '0.29878', '-0.25696', '1.0423', '0.57365', '0.050952', '0.13223', '0.050029', '0.59866', '0.70766', '-0.1512', '-0.3763', '-0.083686', '0.79886', '-0.11396', '0.24633', '0.70494', '-0.64359', '-0.53428', '-0.010697', '0.26435', '1.0684', '0.72634', '0.41096', '0.0613', '-1.4023', '0.27872', '-1.1249', '0.028343', '0.96353', '1.456', '0.080075', '-0.3469', '-0.59024', '-0.84865', '-0.55505', '-0.025072', '0.30641', '0.0019008', '-0.28924', '0.2211', '0.70376', '-1.5813', '0.40594', '0.40736', '0.97715', '-0.93529']\n",
      "['prÿ£⁄æt-ÿ£', '-porter', '-0.46105', '-0.10979', '-0.78657', '-1.4628', '-0.67331', '-0.89428', '0.86064', '-0.47145', '0.69665', '-0.5267', '-0.63135', '0.091663', '-0.204', '-0.40327', '0.1068', '-1.0732', '-0.16869', '0.086456', '0.068008', '-0.15538', '1.0932', '-0.89363', '-0.34919', '-0.17215', '-0.28534', '0.87039', '-1.5417', '-0.09248', '-0.16569', '-0.27514', '-0.86997', '0.43902', '-0.040925', '0.9062', '-0.58926', '0.64349', '0.59196', '0.52413', '-1.1168', '-0.33311', '0.76442', '-1.1423', '0.45072', '-0.63331', '0.049583', '-0.70828', '0.90708', '-0.037268', '0.27319', '0.6244']\n",
      "['ÿ£', 'lex', '-0.74085', '-0.32931', '0.49364', '1.2496', '0.36047', '0.01769', '0.67982', '1.4016', '-1.1244', '-0.18397', '0.52547', '-0.37512', '1.0833', '-0.73306', '0.087918', '-1.2161', '-1.0591', '-0.20374', '0.40432', '-0.62945', '-0.28337', '-0.41262', '0.057733', '0.28145', '0.71002', '1.1607', '1.1748', '-0.44944', '0.22832', '-0.20874', '-0.64964', '-0.002923', '0.87082', '-0.70342', '-1.1208', '-0.36091', '-0.44992', '-0.081009', '-0.1313', '-0.64146', '0.66297', '-0.75952', '0.15175', '0.3792', '-0.88589', '-0.99236', '0.39235', '-1.1428', '0.2296', '0.041193']\n",
      "['bÿ£', 'n', '-0.27165', '0.08387', '-0.10498', '0.88572', '0.92862', '-0.079237', '1.3693', '0.22344', '0.8567', '-0.06643', '-0.36795', '0.48858', '1.1994', '-0.2971', '-0.59846', '0.30558', '0.084593', '0.21402', '0.40191', '1.1584', '-0.18258', '-0.063114', '-0.055943', '0.66854', '0.46899', '0.98664', '0.49353', '-0.41723', '0.0093255', '0.75029', '-0.93298', '-0.011682', '0.31829', '0.55023', '0.57703', '0.28685', '-0.058406', '-1.7592', '-0.80648', '-0.37315', '0.13541', '0.1749', '-1.114', '0.17668', '-0.51127', '-0.22687', '0.32394', '0.36088', '1.0437', '0.30471']\n",
      "['ÿ§‚Äòoÿ£', 'n', '-0.32164', '0.41976', '-0.070797', '-0.41541', '-0.22932', '-0.84868', '0.52603', '0.68681', '-0.21476', '-0.50678', '0.021372', '0.86555', '0.83539', '-0.4603', '-0.50068', '-1.3986', '-1.0012', '0.27969', '1.1411', '0.73509', '-0.60291', '-0.16392', '0.88859', '0.26069', '0.30532', '1.2849', '0.19082', '-0.62654', '0.20635', '0.46503', '-0.89362', '-0.035928', '0.30239', '0.95737', '-0.3547', '0.34005', '-0.70272', '-0.45676', '-0.041776', '0.23195', '0.59721', '-0.78543', '0.50801', '-0.24405', '0.64482', '-0.87799', '-0.1857', '0.14706', '0.41183', '0.46068']\n",
      "['xÿ£', 'tiva', '-0.074362', '-0.16462', '-0.32252', '-0.21606', '-0.60027', '-1.0424', '0.17689', '0.65545', '0.34364', '0.86544', '0.61814', '-0.46189', '0.51522', '-0.77151', '0.043041', '-0.036435', '-0.23993', '-0.011898', '0.36919', '0.070803', '0.66747', '-0.10833', '-0.31286', '0.82309', '-0.51786', '1.2316', '0.0075602', '0.39542', '0.24234', '0.17585', '-1.0193', '-0.81987', '0.31014', '-0.11536', '0.31102', '0.29622', '-0.17698', '0.50143', '-0.12378', '-0.11055', '1.4556', '-0.37907', '0.4306', '-0.39382', '-0.72195', '-0.20632', '0.53467', '-0.47897', '0.13115', '-0.61451']\n",
      "['lÿ£', 'o', '1.029', '-0.29921', '0.16189', '1.7212', '-0.47647', '-0.22656', '0.79694', '1.3222', '-0.79392', '-1.2525', '0.7376', '-0.96321', '-0.33205', '-1.9635', '0.15325', '-0.05421', '-0.37667', '1.0464', '0.95229', '0.67949', '-0.63987', '-0.68541', '-0.26998', '1.3367', '0.738', '0.57817', '0.10612', '0.038139', '-1.1183', '-0.66957', '-0.82241', '0.22477', '0.87872', '-0.063087', '-0.070708', '0.34207', '-1.0206', '1.1909', '0.17762', '-0.10773', '0.92011', '-0.038881', '-0.13367', '-1.1444', '0.49701', '-0.855', '1.2078', '0.60314', '-0.037871', '-0.071542']\n",
      "['hÿ£', 'n', '-0.40023', '-0.034877', '-0.38743', '0.077389', '-1.2905', '-0.60568', '0.86938', '0.25737', '-0.084925', '-0.033282', '-0.0028996', '0.8986', '0.7499', '0.61027', '-0.6146', '0.21543', '-0.58104', '-0.6312', '0.28093', '1.2597', '-0.53651', '-1.6705', '-0.43331', '-0.088062', '0.67363', '0.62727', '0.26685', '-0.059948', '0.40722', '-0.040112', '-0.68322', '-0.92532', '0.71222', '0.76205', '-0.65708', '-0.25558', '0.10366', '-1.0372', '-0.5474', '0.81073', '-0.50758', '-0.61771', '0.032796', '0.59812', '0.05741', '-0.24981', '0.92906', '-0.63719', '-0.25308', '0.023268']\n",
      "['pont-ÿ£', '-mousson', '-0.011568', '-0.42331', '-0.65784', '-0.043084', '-0.40967', '-0.70195', '0.94507', '1.0368', '-0.24794', '0.4313', '-0.059723', '-0.53108', '-0.086104', '-0.66848', '-0.64955', '-0.2328', '-0.8816', '0.10411', '-0.12835', '0.46013', '0.4773', '0.49618', '-0.22977', '0.23428', '-0.05864', '0.30491', '0.34597', '-0.13588', '-0.28214', '-0.44908', '-1.2543', '-0.27321', '0.12482', '-0.46535', '0.49265', '-0.30064', '-0.55265', '0.22339', '0.56128', '0.56505', '0.47783', '-0.20599', '0.051241', '0.19936', '-0.079013', '-0.23557', '1.3825', '-0.14205', '-0.44373', '0.12134']\n",
      "['hÿ£', 'm', '1.1481', '-0.46673', '0.24044', '-0.57974', '-0.1561', '0.76498', '0.93524', '1.4326', '1.0556', '-0.27592', '-0.21329', '-0.19832', '0.45511', '-0.17986', '-0.30412', '-0.20142', '-0.25502', '1.2173', '1.1262', '0.039957', '0.014546', '-1.0519', '-0.76283', '0.42974', '1.3812', '0.12879', '0.74138', '-0.28365', '-0.41964', '0.129', '-1.4138', '-0.63645', '-0.49731', '1.4498', '0.24107', '-0.60876', '-0.37897', '0.99181', '-0.40446', '-0.18077', '-0.17268', '-0.77798', '-0.085786', '-0.32501', '-0.27547', '-0.82999', '0.36571', '-1.5837', '-0.35655', '0.12664']\n",
      "['ÿ§‚Äòÿ£', 'o', '-0.45297', '-1.1206', '-0.45369', '-0.20686', '0.504', '-0.25292', '0.7024', '-0.78601', '0.87774', '-0.094736', '-0.46453', '0.34127', '0.16807', '-0.45653', '0.73068', '-0.5514', '0.38026', '0.12248', '0.86783', '0.33459', '-0.00072733', '-1.0251', '-0.51694', '-0.093584', '0.93835', '1.0673', '0.61537', '-0.38796', '-0.095854', '0.10261', '-1.478', '-0.31898', '0.32567', '1.4513', '-0.9409', '-0.038675', '0.11483', '0.39411', '0.21437', '0.79834', '-0.25583', '0.12706', '-0.46166', '0.25489', '0.42455', '-0.22056', '0.12965', '-0.5122', '0.23412', '0.30294']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cesÿ£', 'ro', '0.30112', '-0.21142', '-0.43027', '0.51877', '-0.36029', '0.111', '1.7371', '0.92315', '-0.10067', '1.5415', '-0.39326', '0.25646', '0.89512', '-0.19802', '0.70913', '-0.90895', '0.8522', '-0.082487', '-0.074469', '-0.27064', '-0.58498', '-1.5199', '0.27816', '-0.79204', '0.78398', '1.201', '0.35222', '-0.046035', '-0.18989', '0.64599', '-1.3025', '0.10218', '-0.67608', '0.64645', '0.1404', '-0.13708', '0.037032', '0.75088', '-0.44159', '-0.53196', '-0.60561', '0.31174', '-1.2573', '0.12892', '-1.1279', '-0.50873', '0.65558', '0.34729', '0.20409', '0.031806']\n",
      "['tÿ£', 'i', '-0.91774', '-0.16903', '-0.17265', '-0.45177', '-0.90707', '-1.1597', '1.1444', '-1.0242', '0.42159', '0.48766', '-1.1305', '0.40264', '0.58208', '-0.80139', '-0.21237', '-0.8138', '-0.13844', '0.58828', '0.84181', '0.7831', '-0.19262', '-0.31952', '0.7844', '0.51714', '0.17414', '0.81509', '-0.20763', '-0.41601', '-0.075051', '-0.61255', '-1.4321', '-0.42953', '-0.87858', '0.075832', '-0.10328', '0.50841', '-0.062013', '-0.2782', '-0.40168', '0.061185', '0.037856', '-0.095093', '-0.28854', '-0.16329', '0.88988', '0.2022', '1.0194', '-0.87496', '0.64367', '0.61915']\n",
      "['sÿ£', 'i', '-0.95875', '-0.93287', '0.20202', '-0.35916', '-0.57573', '-1.1261', '0.56996', '0.83583', '-0.36325', '0.59748', '0.83111', '0.0041141', '1.2113', '0.47667', '0.42168', '-0.034471', '0.54311', '1.0954', '0.35689', '1.0982', '-0.1573', '-0.73005', '0.019143', '1.0263', '-0.078037', '0.72576', '0.96575', '0.35289', '0.44097', '-0.25127', '-1.3004', '-0.060083', '0.81794', '0.51424', '-0.93953', '-0.055525', '0.18655', '-0.51135', '-0.37929', '-0.81795', '0.25839', '-1.2252', '0.68531', '0.307', '-0.044051', '-1.2454', '-0.57268', '0.22796', '0.55115', '0.66278']\n",
      "['bÿ£', 'squet', '1.1462', '0.50728', '-0.70354', '-0.11882', '-1.1185', '-0.7548', '0.37237', '0.70185', '-0.75987', '1.3866', '1.2434', '0.17128', '-0.094544', '-0.25251', '-0.15952', '0.25707', '-0.49229', '0.68078', '-0.1189', '-0.0113', '-0.77555', '0.070483', '-0.55018', '0.90012', '-0.23849', '1.6251', '0.66276', '0.073823', '-0.32326', '0.81084', '-1.2985', '0.291', '-0.085864', '-0.27641', '0.5905', '0.22684', '0.33871', '0.97083', '-0.21132', '0.074824', '1.2846', '-0.92841', '-0.20192', '0.90912', '0.13133', '0.30538', '0.49478', '0.23962', '-0.13492', '-0.56753']\n",
      "['gÿ£', 'idhlig', '-0.78831', '-0.46077', '-0.15363', '-0.0038481', '-0.92163', '-0.35655', '1.1987', '0.5933', '-0.066574', '-0.40277', '-0.18395', '1.0831', '0.38882', '0.29154', '-0.39624', '-0.4898', '0.88716', '0.54977', '0.48916', '0.84131', '-0.168', '-0.95629', '1.4088', '1.2628', '0.40194', '0.94584', '-0.33041', '-0.32021', '-0.87979', '0.67574', '-0.34349', '0.20634', '1.1224', '1.0412', '-0.31064', '0.69371', '-0.29452', '-0.47721', '0.18162', '-0.71983', '0.22193', '-0.1769', '-0.64922', '0.025423', '0.46837', '-0.68219', '0.41782', '0.30438', '0.95546', '0.70228']\n",
      "['riviÿ£¬®re-ÿ£', '-pierre', '-0.098725', '0.20047', '-0.0066253', '-0.75228', '-0.095862', '-0.19956', '0.84678', '0.34309', '0.068041', '0.41737', '0.21178', '-0.18098', '0.72245', '-0.2602', '-0.39721', '-0.012791', '0.52207', '0.36162', '0.42988', '0.93612', '0.48175', '-0.59571', '-0.014177', '0.457', '0.5848', '0.51168', '-0.71401', '0.43982', '-0.38723', '-0.33972', '-1.2276', '-0.51498', '0.53684', '-0.11447', '-0.66074', '0.0076807', '-0.13281', '-0.47219', '0.25265', '0.68204', '0.22589', '-0.62588', '-0.32528', '0.11784', '-0.50046', '-0.61329', '0.36959', '0.34942', '0.26727', '-0.99017']\n",
      "['jiÿ£', 'n', '-0.56116', '-0.60344', '-0.56132', '0.028474', '-0.24698', '-0.54479', '1.0729', '-0.53716', '-0.67078', '0.79074', '0.21018', '1.3619', '0.67524', '0.47191', '0.59812', '-0.55076', '-0.24809', '0.69782', '-0.027937', '0.95503', '-0.37315', '0.10661', '-0.036009', '-0.032039', '0.99934', '0.52791', '0.54871', '-0.95571', '-1.1419', '0.051125', '-1.3153', '-0.19218', '0.068922', '0.67668', '-0.75597', '0.22342', '-0.26123', '-0.81002', '-0.77657', '-0.10598', '-0.3308', '0.55662', '-0.37226', '-0.060756', '0.36724', '-0.65664', '0.43698', '-0.42786', '0.05991', '0.54279']\n",
      "['rÿ£', 'dio', '-1.3493', '0.24762', '0.95719', '0.46994', '-1.2976', '-0.91228', '0.19122', '1.271', '-0.22665', '0.085562', '0.23919', '-0.96032', '0.03779', '-0.20759', '-0.31454', '-0.44862', '-0.3745', '0.57466', '0.37636', '-0.69102', '-0.2101', '-0.28219', '0.27585', '0.87238', '1.2514', '1.0966', '0.037905', '0.43088', '0.097283', '-0.23878', '-1.0464', '0.32639', '-0.24852', '-0.13254', '-1.4033', '-0.48814', '0.4924', '0.81156', '0.48828', '0.39545', '1.3272', '-1.1484', '-0.69276', '0.2725', '-0.40981', '0.46536', '0.11494', '0.16741', '0.52914', '0.040174']\n",
      "['dÿ£', 'i', '-1.2181', '0.54413', '-0.92563', '-0.70488', '-0.55267', '-0.53888', '0.54657', '0.0049052', '0.3237', '-0.4774', '0.44711', '0.53497', '1.6164', '1.0041', '-0.60592', '-0.14649', '0.072755', '0.51055', '0.28527', '-0.32416', '-1.0441', '-0.2018', '-0.95346', '0.32995', '0.66901', '0.782', '0.24188', '0.27565', '0.039129', '-0.23176', '-1.3639', '0.0015058', '-0.27759', '0.64268', '-0.42465', '-0.15315', '0.46846', '-0.66776', '-1.052', '-0.10696', '0.21409', '-0.40924', '0.60372', '0.13923', '0.044407', '-0.51215', '0.71497', '-0.010349', '-0.39676', '0.91946']\n",
      "['ngÿ£', 'y', '-0.38737', '0.019359', '0.23645', '-0.39014', '-0.83472', '-1.2045', '1.3025', '0.10474', '0.692', '0.059171', '-0.39509', '-0.23401', '0.71851', '0.12813', '0.081767', '0.19073', '0.292', '0.23904', '0.55869', '0.54818', '-0.32299', '-0.083459', '0.35478', '0.69097', '0.63082', '1.1447', '-0.047106', '-0.066614', '-0.13118', '0.46686', '-0.95798', '0.50589', '-0.33984', '0.90788', '-0.64148', '-0.41578', '0.61951', '-0.77295', '0.44201', '0.053306', '-0.14417', '-0.47692', '0.14459', '-0.11428', '0.22824', '-0.1407', '0.43719', '0.16045', '1.0011', '1.277']\n",
      "['hÿ£', 'nh', '-0.047789', '-0.43346', '-0.081588', '-0.76187', '-0.57003', '-0.32435', '1.0695', '1.0832', '-0.063291', '-0.86214', '-0.22002', '1.1565', '-0.17199', '-0.56405', '0.18737', '-0.23012', '0.23122', '-0.23455', '0.72294', '1.1559', '-0.94538', '-1.2132', '-0.1706', '0.069041', '0.89688', '0.49027', '-0.3493', '-0.097009', '0.41765', '-0.3566', '-1.4517', '-0.7146', '0.71356', '0.85971', '-0.44958', '0.52765', '0.61974', '-0.4368', '-0.32977', '0.5382', '0.2969', '-0.75691', '0.34855', '0.09438', '-0.23503', '0.023582', '0.33826', '0.3714', '-0.38312', '0.17731']\n",
      "['ÿ£¬Æle-ÿ£', '-la-crosse', '0.093835', '0.12326', '-0.51472', '-0.28339', '-0.81188', '-0.75913', '0.47303', '0.92138', '0.39363', '0.099465', '0.043099', '-0.23146', '0.96231', '-0.88873', '-0.90811', '0.58602', '-0.4158', '0.70132', '0.42856', '0.11286', '0.97478', '-0.24114', '0.37473', '0.029517', '-0.03849', '0.089753', '0.36404', '0.9915', '-0.37132', '-0.51596', '-1.4715', '0.47753', '0.18191', '0.62903', '0.076112', '-0.70628', '-0.38129', '0.49967', '-0.10254', '0.60019', '0.69164', '-0.44139', '-0.47458', '0.051616', '-0.0044881', '-0.7231', '0.059482', '0.29258', '-0.49884', '-0.12764']\n",
      "['benicÿ£', 'ssim', '0.21162', '-0.62605', '-1.6048', '0.38804', '-0.68171', '-1.2779', '0.56943', '-0.065435', '0.47946', '1.5345', '0.51713', '-0.46449', '0.84459', '-0.30232', '0.23865', '-0.69875', '-0.47589', '-0.49125', '-0.06963', '-0.02111', '0.49294', '-1.016', '-0.16519', '0.49251', '-0.57449', '1.0562', '0.14837', '0.21212', '-0.19033', '-0.18801', '-1.0025', '-0.00526', '-1.0053', '-0.33487', '-0.50377', '-0.94206', '-0.38819', '0.29411', '0.035403', '0.74092', '-0.2032', '-0.35177', '-0.031033', '-0.32327', '-0.1924', '-0.1595', '0.82799', '-0.80916', '0.63421', '-0.02698']\n",
      "['lÿ£', 'ng', '-0.72477', '0.55373', '0.52466', '-0.20832', '-0.12702', '-0.82739', '0.96672', '-0.49085', '-0.25105', '-0.17962', '-0.03801', '-0.27398', '0.92453', '-0.31565', '-0.20586', '0.26307', '0.16536', '1.2596', '0.83952', '0.99957', '-0.49294', '0.31545', '0.079835', '0.93503', '-0.11355', '1.0924', '-0.20202', '-0.044911', '0.24028', '0.54708', '-0.94522', '-0.14021', '-0.58888', '1.4215', '-0.30031', '0.32053', '0.105', '-1.3717', '-0.14261', '0.40102', '0.60057', '-0.20115', '-0.35309', '0.13636', '0.25177', '-1.1299', '0.010067', '0.28135', '0.55819', '0.38718']\n",
      "['Ÿä‚Äì‚Ä∞Ÿâ', '‚Ä¢√´⁄à‚Ñ¢', '-0.2329', '-0.28264', '0.45301', '-0.30687', '-0.89357', '-1.7641', '2.0869', '-0.52583', '0.67219', '-0.3278', '0.7725', '0.50153', '0.50306', '-0.44088', '-1.0328', '0.41885', '-0.17384', '0.81782', '1.2613', '1.309', '-0.26581', '-0.65411', '-0.77601', '-0.90186', '-0.7766', '0.33899', '1.149', '-0.38442', '-1.4324', '1.0179', '-0.17977', '-0.064294', '0.10158', '1.5785', '-0.95412', '0.15106', '0.12631', '0.11358', '0.077421', '-0.17815', '0.77042', '-0.11854', '0.63951', '0.26074', '-1.2166', '-1.0643', '-0.053917', '0.77156', '-0.16221', '0.16132']\n",
      "['hÿ£', 'ng', '-0.54441', '0.47542', '0.49479', '-0.69628', '-0.52651', '-1.3072', '1.1258', '0.18855', '-0.55323', '-0.13095', '-0.50468', '-0.45069', '0.19815', '0.14302', '-0.44526', '-0.0011643', '0.51264', '0.65651', '0.66218', '0.2437', '-0.49349', '-0.45616', '-0.51711', '1.0486', '0.16558', '1.5867', '0.11876', '0.59521', '0.4844', '0.50131', '-1.262', '-0.0508', '0.60829', '0.85443', '-0.47285', '-0.16044', '-0.046421', '-0.62127', '-0.44688', '0.3603', '0.38151', '-0.52453', '0.53904', '-0.24721', '-0.0157', '0.059261', '0.25498', '0.049084', '0.14978', '0.59034']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bÿ£', 'i', '-0.69114', '-0.36784', '0.27272', '-0.31153', '-0.40625', '-1.1587', '1.1166', '1.1215', '-0.19395', '0.060731', '-0.22906', '0.45915', '1.0973', '-0.17676', '0.22611', '0.34855', '0.38124', '0.59652', '1.0368', '0.062082', '0.25846', '0.42306', '0.8348', '0.84207', '0.38536', '0.78274', '0.56774', '-0.12719', '0.63814', '-0.32774', '-1.1792', '0.23993', '-0.50177', '-0.081727', '-0.77571', '-0.38089', '-0.36085', '-0.71218', '0.39964', '-0.59135', '0.45724', '-0.68047', '0.60185', '0.44231', '-0.12314', '-0.42184', '-0.011937', '0.79402', '0.53224', '1.3521']\n",
      "['ÿ§‚Äòÿ£', 'm', '-0.88771', '-0.60298', '-0.33635', '-0.37724', '0.37188', '-0.62391', '0.92491', '0.35512', '0.27129', '-0.21732', '-0.086892', '-0.42216', '0.62195', '-0.1695', '0.064419', '0.18047', '0.2759', '0.52071', '0.54637', '0.32723', '0.18244', '-0.05291', '-0.29827', '-0.26061', '0.64372', '0.80397', '0.43386', '0.096627', '-0.21127', '-1.0704', '-1.7387', '-0.26759', '-0.012017', '1.1361', '0.011154', '-0.01715', '0.25265', '0.12701', '0.41959', '1.1688', '-0.22546', '-0.23274', '0.065791', '0.047463', '-0.037904', '-1.1515', '0.52191', '-0.27162', '-0.48543', '0.074934']\n",
      "['zhÿ£', 'o', '-1.1364', '0.21403', '-0.013368', '-0.23927', '-0.48686', '-0.22161', '0.84763', '0.22837', '-0.93932', '0.4167', '0.55954', '1.0439', '0.62966', '-0.050143', '0.53318', '0.11465', '-0.25881', '0.032743', '0.9401', '0.52712', '-0.65083', '-0.097441', '0.19816', '1.205', '1.1104', '0.681', '-0.10813', '-0.84923', '0.055231', '0.35545', '-1.3549', '0.05686', '-0.1274', '0.27058', '0.062236', '0.021043', '-0.18511', '-0.21266', '-0.092435', '-0.079936', '0.40159', '-0.17889', '0.65941', '-0.030281', '0.39122', '0.32792', '0.49295', '0.14252', '1.1849', '0.31469']\n",
      "['√´¬≤‚Ä¢Ÿâ', '‚Ä¢√´⁄à‚Ñ¢', '0.23964', '-0.33579', '0.52571', '-0.51157', '-1.2512', '-1.2852', '1.2933', '-0.14557', '0.96828', '0.14272', '0.18215', '0.40723', '0.96859', '-0.69065', '-0.19445', '0.28343', '0.25787', '0.21785', '0.40481', '1.1238', '-0.17934', '-0.55252', '-0.2071', '-0.70735', '-0.56407', '-0.45212', '0.87581', '-1.0133', '-1.6835', '0.87096', '-0.13603', '-0.46716', '-0.55047', '1.3809', '-0.7024', '-0.16754', '0.14353', '0.11956', '0.18288', '-0.94011', '0.72361', '-0.14512', '0.78867', '1.4819', '-1.3915', '-1.1905', '-0.040754', '0.98322', '-0.17641', '-0.4231']\n",
      "['ÿ£', 'i', '-0.59582', '0.7349', '0.01749', '-0.57599', '-0.96072', '-1.1074', '1.0337', '0.29689', '-0.24256', '0.49861', '0.24322', '0.9445', '0.51648', '0.36215', '0.22458', '-0.84392', '0.40772', '0.32239', '0.84855', '0.0533', '-0.83039', '-0.60944', '0.34305', '0.75614', '0.67974', '1.3647', '-0.087328', '0.089095', '0.37283', '0.1063', '-1.2409', '0.26241', '0.2715', '0.97117', '-0.98159', '-0.2019', '-0.13875', '-0.37118', '-0.28617', '-0.0048383', '0.78338', '-1.0972', '1.404', '0.068256', '0.25171', '-0.45437', '0.2965', '0.12821', '0.73071', '0.61396']\n",
      "['dÿ£', 'o', '-0.34753', '-0.12654', '-0.036263', '-0.13663', '-0.65058', '-1.01', '1.3011', '0.36457', '-0.29005', '-0.12571', '-0.17402', '0.7618', '0.81714', '0.37556', '-0.10744', '-0.51259', '0.13345', '0.47033', '0.85059', '0.14197', '-0.48677', '-0.57025', '0.037643', '0.72087', '1.3497', '1.0516', '-0.24919', '-0.048712', '0.58848', '-0.34051', '-0.85826', '-0.13764', '-0.24887', '0.77687', '-0.92713', '0.14574', '-0.040994', '-0.62959', '-0.3553', '0.10676', '0.36469', '-0.70496', '0.77779', '-0.27966', '0.30945', '-0.031626', '0.72232', '-0.04097', '0.8124', '0.67663']\n"
     ]
    }
   ],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1943,
     "status": "ok",
     "timestamp": 1611738728468,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "buYjsIBecFIs"
   },
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (J,), where J can be any number\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get a valid word contained in the word_to_vec_map. \n",
    "    any_word = list(word_to_vec_map.keys())[0]\n",
    "    words = sentence.lower().split()\n",
    "    avg = np.zeros(word_to_vec_map[any_word].shape)\n",
    "    count = 0\n",
    "\n",
    "    for w in words:\n",
    "        if w in word_to_vec_map:\n",
    "            avg += word_to_vec_map[w]\n",
    "            count +=1\n",
    "          \n",
    "    if count > 0:\n",
    "        avg = avg / count\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2322,
     "status": "ok",
     "timestamp": 1611738741724,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "O_BzrO-TcFIv"
   },
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    \"\"\"\n",
    "    Model to train word vector representations in numpy.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, numpy array of sentences as strings, of shape (m, 1)\n",
    "    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    learning_rate -- learning_rate for the stochastic gradient descent algorithm\n",
    "    num_iterations -- number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    pred -- vector of predictions, numpy-array of shape (m, 1)\n",
    "    W -- weight matrix of the softmax layer, of shape (n_y, n_h)\n",
    "    b -- bias of the softmax layer, of shape (n_y,)\n",
    "    \"\"\"\n",
    "    \n",
    "    any_word = list(word_to_vec_map.keys())[0]\n",
    "    cost = 0\n",
    "    \n",
    "    m = Y.shape[0]                             # number of training examples\n",
    "    n_y = len(np.unique(Y))                    # number of classes  \n",
    "    n_h = word_to_vec_map[any_word].shape[0]   # dimensions of the GloVe vectors \n",
    "    \n",
    "    # Initialize parameters using Xavier initialization\n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    # Convert Y to Y_onehot with n_y classes\n",
    "    Y_oh = convert_to_one_hot(Y, C = n_y) \n",
    "    \n",
    "    # Optimization loop\n",
    "    for t in range(num_iterations): # Loop over the number of iterations\n",
    "        for i in range(m):          # Loop over the training examples\n",
    "    \n",
    "            # Average the word vectors of the words from the i'th training example\n",
    "            avg = sentence_to_avg(X[i], word_to_vec_map)\n",
    "\n",
    "            # Forward propagate the avg through the softmax layer. \n",
    "            z = np.dot(W,avg)+b\n",
    "            a = softmax(z)\n",
    "\n",
    "            # Compute cost using the i'th training label's one hot representation and a\n",
    "            cost = np.sum(Y_oh[i] * np.log(a))\n",
    "            \n",
    "            # Compute gradients \n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "\n",
    "            # Update parameters with Stochastic Gradient Descent\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map) #predict is defined in emo_utils.py\n",
    "\n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3817,
     "status": "ok",
     "timestamp": 1611738757775,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "umWTqRcpcFIw",
    "outputId": "7b74cb94-e98c-4936-98bc-693a3bb5f34e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = -1.9520498812810072\n",
      "Accuracy: 0.3484848484848485\n",
      "Epoch: 100 --- cost = -0.07971818726014807\n",
      "Accuracy: 0.9318181818181818\n",
      "Epoch: 200 --- cost = -0.04456369243681402\n",
      "Accuracy: 0.9545454545454546\n",
      "Epoch: 300 --- cost = -0.03432267378786059\n",
      "Accuracy: 0.9696969696969697\n",
      "[[3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3704,
     "status": "ok",
     "timestamp": 1611738776291,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "yhb6CzhrcFIx",
    "outputId": "08d07fd0-55c2-4eff-d570-2562deb0570b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9772727272727273\n",
      "Test set:\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1909,
     "status": "ok",
     "timestamp": 1611738785398,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "tvCl7fUvcFIz",
    "outputId": "a3913da3-85df-466d-dd8f-520245d495fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "i adore you ‚ù§Ô∏è\n",
      "i love you ‚ù§Ô∏è\n",
      "funny lol üòÑ\n",
      "lets play with a ball ‚öæ\n",
      "food is ready üç¥\n",
      "not feeling happy üòÑ\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyC-BGqKcFI0"
   },
   "source": [
    "#### Word Ordering isn't  considered in this Model\n",
    "* Note that the model doesn't get the following sentence correct:\n",
    ">\"not feeling happy\" \n",
    "\n",
    "* This algorithm ignores word ordering, so is not good at understanding phrases like \"not happy.\" \n",
    "\n",
    "#### Confusion Matrix\n",
    "* Printing the confusion matrix can also help understand which classes are more difficult for your model. \n",
    "* A confusion matrix shows how often an example whose label is one class (\"actual\" class) is mislabeled by the algorithm with a different class (\"predicted\" class).\n",
    "\n",
    "Print the confusion matrix below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "executionInfo": {
     "elapsed": 2061,
     "status": "ok",
     "timestamp": 1611738816883,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "Ab9aH9IQcFI1",
    "outputId": "d8cfc4cc-bbdc-487b-8efc-3d9a3cdbdd06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n",
      "           ‚ù§Ô∏è    ‚öæ    üòÑ    üòû   üç¥\n",
      "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
      "Actual                                 \n",
      "0            6    0    0    1    0    7\n",
      "1            0    8    0    0    0    8\n",
      "2            2    0   16    0    0   18\n",
      "3            1    1    2   12    0   16\n",
      "4            0    0    1    0    6    7\n",
      "All          9    9   19   13    6   56\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Y_test.shape)\n",
    "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
    "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "plot_confusion_matrix(Y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEeTqpjlcFI2"
   },
   "source": [
    "<a name='2'></a>\n",
    "## Emojifier-V2: Using LSTMs in Keras \n",
    "\n",
    "Build an LSTM model that takes word **sequences** as input! This model will be able to account for word ordering. \n",
    "\n",
    "Emojifier-V2 will continue to use pre-trained word embeddings to represent words. then feed word embeddings into an LSTM, and the LSTM will learn to predict the most appropriate emoji. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 2501,
     "status": "ok",
     "timestamp": 1611738953388,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "uZ-fy9fYcFI3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "np.random.seed(0)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7LJvriXcFI3"
   },
   "source": [
    "<a name='2-1'></a>\n",
    "### Model Overview\n",
    "\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center><font color='purple'><b>Figure</b>: Emojifier-V2. A 2-layer LSTM sequence classifier. </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 2881,
     "status": "ok",
     "timestamp": 1611738972334,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "Z0SixlIwcFI5"
   },
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). \n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m, 1)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                                   # number of training examples    \n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    \n",
    "    for i in range(m):                               # loop over training examples\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                j =  j + 1\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1992,
     "status": "ok",
     "timestamp": 1611738982161,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "oBL1PMOCcFI6",
    "outputId": "6781359c-bafd-4ab5-a477-f8a5a86ea219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
      "X1_indices =\n",
      " [[155338. 225108.      0.      0.      0.]\n",
      " [220916. 286359.  69714.      0.      0.]\n",
      " [151197. 192959. 302238. 151342. 394457.]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "X1_indices = sentences_to_indices(X1, word_to_index, max_len=5)\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\\n\", X1_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 2160,
     "status": "ok",
     "timestamp": 1611738992486,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "XBlEpiVkcFI7"
   },
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1             \n",
    "    any_word = list(word_to_vec_map.keys())[0]\n",
    "    emb_dim = word_to_vec_map[any_word].shape[0]    \n",
    "      \n",
    "    emb_matrix = np.zeros((vocab_size, emb_dim))\n",
    "    \n",
    "    for word, idx in word_to_index.items():\n",
    "        try:\n",
    "            emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "        except:\n",
    "            print(word)\n",
    "    \n",
    "    embedding_layer = Embedding(input_dim = vocab_size, output_dim = emb_dim)\n",
    "    \n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEsWnZ_2cFI7"
   },
   "source": [
    "<a name='2-4'></a>\n",
    "### Building the Emojifier-V2\n",
    "\n",
    "Build the Emojifier-V2 model, in which  he embedding layer's output is fed to an LSTM network!\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center><font color='purple'><b>Figure</b>: Emojifier-v2. A 2-layer LSTM sequence classifier. </center></caption></font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 3214,
     "status": "ok",
     "timestamp": 1611739012958,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "Pb2ugsSUcFI7"
   },
   "outputs": [],
   "source": [
    "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Function creating the Emojify-v2 model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence_indices = Input(shape = input_shape, dtype = 'int32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    X = LSTM(128,return_sequences = True)(embeddings)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = LSTM(128,return_sequences = False)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(5)(X)\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(sentence_indices,X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3127,
     "status": "ok",
     "timestamp": 1611739019596,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "8fLhXJ9ucFI8",
    "outputId": "02d98359-a43b-4780-bb17-3d36e060aa86",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benicÿ£\n",
      "carnivÿ£\n",
      "cesÿ£\n",
      "fÿ£\n",
      "gimnÿ£\n",
      "grÿ£\n",
      "gÿ£\n",
      "jiÿ£\n",
      "ngÿ£\n",
      "pointe-ÿ£\n",
      "pont-ÿ£\n",
      "prÿ£⁄æt-ÿ£\n",
      "riviÿ£¬®re-ÿ£\n",
      "rÿ£\n",
      "sÿ£\n",
      "thÿ£\n",
      "toÿ£\n",
      "tÿ£\n",
      "vis-ÿ£\n",
      "xiÿ£\n",
      "xÿ£\n",
      "zhÿ£\n",
      "√´¬≤‚Ä¢Ÿâ\n",
      "ÿ£¬Æle-ÿ£\n",
      "ÿ§‚Äòoÿ£\n",
      "Ÿá⁄Ø≈íŸÜ¬∏¬≠Ÿà‚Ä∫¬∏√©‚Äì‚Ç¨ŸÜ¬∏‚ÄπŸá¬π¬≥√ß¬´\n",
      "Ÿä‚Äì‚Ä∞Ÿâ\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 10, 50)            19998850  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,222,727\n",
      "Trainable params: 20,222,727\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 2041,
     "status": "ok",
     "timestamp": 1611739024847,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "aMf79f45cFI9"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 2284,
     "status": "ok",
     "timestamp": 1611739029525,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "UgsBnWQqcFI-"
   },
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "LtFpvyJicFI_",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 270ms/step - loss: 1.5663 - accuracy: 0.2576\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 1s 269ms/step - loss: 1.4908 - accuracy: 0.3636\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 1s 272ms/step - loss: 1.4756 - accuracy: 0.3258\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 2s 315ms/step - loss: 1.3747 - accuracy: 0.3939\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 1s 277ms/step - loss: 1.2689 - accuracy: 0.5455\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 2s 386ms/step - loss: 1.1068 - accuracy: 0.5985\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 2s 325ms/step - loss: 0.9783 - accuracy: 0.6288\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 2s 332ms/step - loss: 0.8168 - accuracy: 0.7045\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 2s 451ms/step - loss: 0.7469 - accuracy: 0.7197\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 2s 481ms/step - loss: 0.6215 - accuracy: 0.7955\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 2s 475ms/step - loss: 0.5726 - accuracy: 0.7652\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 2s 451ms/step - loss: 0.4607 - accuracy: 0.7955\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 1s 285ms/step - loss: 0.3920 - accuracy: 0.8636\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 2s 302ms/step - loss: 0.3433 - accuracy: 0.8712\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 2s 369ms/step - loss: 0.2712 - accuracy: 0.9015\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 2s 304ms/step - loss: 0.1956 - accuracy: 0.9470\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 1s 296ms/step - loss: 0.1585 - accuracy: 0.9470\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 1s 283ms/step - loss: 0.1122 - accuracy: 0.9773\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 1s 286ms/step - loss: 0.1092 - accuracy: 0.9697\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 2s 372ms/step - loss: 0.0752 - accuracy: 0.9848\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 2s 366ms/step - loss: 0.0659 - accuracy: 0.9773\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 2s 403ms/step - loss: 0.1218 - accuracy: 0.9545\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 2s 339ms/step - loss: 0.4115 - accuracy: 0.8939\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 2s 325ms/step - loss: 0.3661 - accuracy: 0.8864\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 2s 370ms/step - loss: 0.4355 - accuracy: 0.8864\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 2s 438ms/step - loss: 0.4488 - accuracy: 0.8712\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 2s 425ms/step - loss: 0.1320 - accuracy: 0.9545\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 2s 348ms/step - loss: 0.2385 - accuracy: 0.9470\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 2s 346ms/step - loss: 0.1208 - accuracy: 0.9924\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 1s 288ms/step - loss: 0.0831 - accuracy: 0.9924\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 1s 295ms/step - loss: 0.0538 - accuracy: 0.9924\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 1s 299ms/step - loss: 0.0521 - accuracy: 0.9924\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 2s 302ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 1s 295ms/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 1s 287ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 1s 284ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 1s 280ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 1s 291ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 2s 301ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 1s 295ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 1s 290ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 2s 320ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 2s 319ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 1s 288ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 1s 291ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 1s 291ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 1s 299ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 1s 286ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 1s 286ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 1s 290ms/step - loss: 0.0035 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2353ae24fd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2962,
     "status": "ok",
     "timestamp": 1611739058762,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "sIbcdVibcFJA",
    "outputId": "65b06e6c-415e-4038-c6fd-3839b3fd39f1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.8036\n",
      "\n",
      "Test accuracy =  0.8035714030265808\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1779,
     "status": "ok",
     "timestamp": 1611739122633,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "mjMyEGmYcFJC",
    "outputId": "0e87d217-d501-40d1-a6c7-71d567643d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji:üòÑ prediction: she got me a nice present\t‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: work is hard\tüòÑ\n",
      "Expected emoji:üòû prediction: This girl is messing with me\t‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: work is horrible\tüòÑ\n",
      "Expected emoji:üç¥ prediction: any suggestions for dinner\tüòÑ\n",
      "Expected emoji:üòÑ prediction: you brighten my day\t‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: she is a bully\tüòÑ\n",
      "Expected emoji:üòÑ prediction: will you be my valentine\t‚ù§Ô∏è\n",
      "Expected emoji:üòÑ prediction: dance with me\t‚ù§Ô∏è\n",
      "Expected emoji:üòÑ prediction: I like to laugh\t‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: go away\t‚öæ\n"
     ]
    }
   ],
   "source": [
    "# This code allows you to see the mislabelled examples\n",
    "C = 5\n",
    "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != Y_test[i]):\n",
    "        print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tT53ibgFcFJE"
   },
   "source": [
    "#### LSTM Version Accounts for Word Order\n",
    "* The Emojify-V1 model did not \"not feeling happy\" correctly, but your implementation of Emojify-V2 got it right! \n",
    "    * If it didn't, be aware that Keras' outputs are slightly random each time, so this is probably why. \n",
    "* The current model still isn't very robust at understanding negation (such as \"not happy\")\n",
    "    * This is because the training set is small and doesn't have a lot of examples of negation. \n",
    "    * If the training set were larger, the LSTM model would be much better than the Emojify-V1 model at understanding more complex sentences. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "zhyVzuThcFI4",
    "LUSzrFkYcFJF"
   ],
   "name": "Solution_Emojify_v2a.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "DLSC5W2-A2"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
